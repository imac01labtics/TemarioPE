<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Temario Probabilidad y Estad√≠stica</title>
    <!-- Recursos -->
    <link rel="icon" href="img/icon.ico" type="image/x-icon">
    <link rel="stylesheet" href="style.css">
    <!-- MathJax permite renderizar formato LaTeX -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Incluir la fuente de KaTeX -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
    <!-- Include Highlight.js CSS for Monokai theme -->
    <link rel="stylesheet"
        href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/stackoverflow-light.min.css">
</head>

<body>
    <div>
        <table id="main-table" style="width: 90%;">
            <!-- #####################################  TEMA 1 ##################################### -->

            <tr>
                <th colspan="2">
                    <h3>Tema 1: Estad√≠stica descriptiva</h3>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>1.1 Conceptos b√°sicos de estad√≠stica</td>
                <td>
                    Definici√≥n: La estad√≠stica es la disciplina que se encarga de recopilar, organizar, analizar e
                    interpretar datos para la toma de decisiones. <br>
                    Teor√≠a de decisi√≥n: M√©todo estad√≠stico para tomar decisiones considerando la incertidumbre y las
                    probabilidades. <br>
                    Poblaci√≥n: Conjunto completo de elementos o individuos sujetos a estudio. <br>
                    Muestra aleatoria: Subconjunto representativo de la poblaci√≥n, seleccionado de manera que cada
                    individuo tenga igual probabilidad de ser incluido. <br>
                    Par√°metros aleatorios: Valores desconocidos que describen caracter√≠sticas de una poblaci√≥n. <br>
                </td>
            </tr>
            <tr>
                <td>1.2 Descripci√≥n de datos</td>
                <td>
                    Datos agrupados y no agrupados: Los datos no agrupados son aquellos que se presentan
                    individualmente, mientras que los datos agrupados est√°n organizados en categor√≠as o intervalos. <br>
                    Frecuencia de clase: La frecuencia de clase es el n√∫mero de veces que se observa un valor dentro de
                    un intervalo particular en un conjunto de datos agrupados. <br>
                    Frecuencia relativa: La frecuencia relativa es la proporci√≥n o porcentaje de veces que ocurre un
                    valor dentro de un conjunto de datos. <br>
                    Punto medio: El punto medio es el valor medio de un intervalo en datos agrupados. <br>
                    L√≠mites: Los l√≠mites son los valores extremos de un intervalo en datos agrupados. <br>
                </td>
            </tr>
            <tr>
                <td>1.3 Medidas de tendencia central</td>
                <td>
                    Media aritm√©tica: Es el promedio com√∫nmente utilizado, obtenido sumando todos los valores y
                    dividiendo esa suma por la cantidad de valores. <br>
                    Media geom√©trica: Es el promedio obtenido multiplicando todos los valores y luego tomando la ra√≠z
                    n-√©sima del producto, donde n es el n√∫mero total de valores. <br>
                    Media ponderada: Es un promedio donde cada valor tiene un peso asignado. Se calcula multiplicando
                    cada valor por su respectivo peso, sumando estos productos y dividiendo por la suma de los pesos.
                    <br>
                    Mediana: Valor central de un conjunto de datos ordenados. <br>
                    Moda: Valor m√°s frecuente en un conjunto de datos. <br>
                    Medidas de dispersi√≥n: Indican la variabilidad de los datos respecto a una medida central. <br>
                    Varianza: Es una medida de dispersi√≥n que indica cu√°nto se alejan los valores de una serie de datos
                    de su media. Se calcula como el promedio de las diferencias al cuadrado entre cada dato y la media.
                    <br>
                    Desviaci√≥n est√°ndar: Es la ra√≠z cuadrada de la varianza. Proporciona una medida de dispersi√≥n
                    similar a la varianza, pero en la misma escala que los datos originales. <br>
                    Desviaci√≥n media: Es la media de las diferencias absolutas entre cada dato y la media. Proporciona
                    una medida de dispersi√≥n que considera tanto los valores por encima como por debajo de la media.
                    <br>
                    Desviaci√≥n mediana: Es la mediana de las diferencias absolutas entre cada dato y la mediana. Es
                    menos sensible a valores extremos que la desviaci√≥n media, lo que la hace √∫til en conjuntos de datos
                    con valores at√≠picos. <br>
                    Rango: Es la diferencia entre el valor m√°ximo y el valor m√≠nimo en un conjunto de datos. Es una
                    medida simple de dispersi√≥n que puede proporcionar una idea general de la amplitud de los datos.
                    <br>
                </td>
            </tr>
            <tr>
                <td>1.4 Par√°metros para datos agrupados</td>
                <td>
                    Este tema se centra en los m√©todos para calcular par√°metros estad√≠sticos, como la media y la
                    varianza, cuando los datos est√°n agrupados en intervalos en lugar de ser valores individuales. Esto
                    es importante porque muchos conjuntos de datos son demasiado grandes para analizar cada valor
                    individualmente, por lo que se agrupan en intervalos para facilitar su an√°lisis.
                </td>
            </tr>
            <tr>
                <td>1.5 Distribuci√≥n de frecuencias</td>
                <td>
                    Se aborda c√≥mo organizar los datos en categor√≠as o intervalos y contar cu√°ntas observaciones caen en
                    cada categor√≠a. La distribuci√≥n de frecuencias proporciona una forma clara de comprender la
                    distribuci√≥n de los datos y es fundamental para calcular estad√≠sticas descriptivas y hacer
                    inferencias sobre la poblaci√≥n a partir de una muestra.
                </td>
            </tr>
            <tr>
                <td>1.6 T√©cnicas de agrupaci√≥n de datos</td>
                <td>
                    Se exploran los m√©todos para agrupar datos en intervalos o categor√≠as de manera significativa y
                    √∫til. Esto puede incluir el uso de reglas espec√≠ficas para determinar el ancho de los intervalos y
                    garantizar que la agrupaci√≥n refleje adecuadamente la distribuci√≥n de los datos.
                </td>
            </tr>
            <tr>
                <td>1.7 T√©cnicas de muestreo</td>
                <td>En el desarrollo de este tema se examinan los diferentes m√©todos para seleccionar una muestra
                    representativa de una poblaci√≥n m√°s grande. Estas t√©cnicas son cruciales para garantizar que la
                    muestra captura adecuadamente la variabilidad y caracter√≠sticas de la poblaci√≥n, lo que permite
                    hacer inferencias precisas sobre la poblaci√≥n a partir de la muestra seleccionada.</td>
            </tr>
            <tr>
                <td>1.8 Histogramas</td>
                <td>
                    Parecidos a los gr√°ficos de barras, estos muestran la distribuci√≥n de frecuencias de un conjunto de
                    datos. <br>
                    Ayudan a visualizar la forma y dispersi√≥n de los datos, identificando patrones y tendencias. Son
                    √∫tiles para datos agrupados y continuos.
                </td>
            </tr>

            <!-- #####################################  TEMA 2 ##################################### -->

            <tr>
                <th colspan="2">
                    <h3>Tema 2: Fundamentos de la Teor√≠a de Probabilidad</h3>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>2.1 T√©cnicas de Conteo</td>
                <td>
                    <p>
                        Las t√©cnicas de conteo son m√©todos utilizados para determinar el n√∫mero de posibles resultados o eventos en un conjunto
                        dado. Estas t√©cnicas son fundamentales en la teor√≠a de probabilidad para calcular probabilidades y analizar eventos
                        complejos. Incluyen la notaci√≥n factorial, los principios multiplicativo y aditivo, permutaciones, combinaciones y el
                        uso de diagramas de √°rbol.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.1 Principio aditivo</td>
                <td>
                    <p>
                        El principio aditivo establece que si dos operaciones son mutuamente excluyentes (no pueden ocurrir simult√°neamente),
                        entonces el n√∫mero total de formas en que se pueden realizar ambas operaciones es la suma de las formas individuales.
                        <br>
                        Si una operaci√≥n puede realizarse en m formas y otra en n y ambas no pueden realizarse juntas, entonces el n√∫mero total 
                        de formas en las que se pueden realizar es <i>m + n</i>.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.2 Principio Multiplicativo</td>
                <td>
                    <p>
                        El principio multiplicativo indica que si una operaci√≥n puede realizarse de <i>m</i> formas y otra operaci√≥n de <i>n</i>
                        formas, entonces ambas operaciones pueden realizarse juntas de <i>m ‚ãÖ n</i> formas.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.3 Notaci√≥n Factorial</td>
                <td>
                    <p>
                        La notaci√≥n factorial se utiliza para representar el producto de todos los enteros positivos hasta un n√∫mero dado <i>n</i>.
                        <br>
                        <i>n</i>! = <i>n</i> ‚ãÖ (<i>n</i> - 1) ‚ãÖ (<i>n</i> - 2) ‚ãÖ ... ‚ãÖ 3 ‚ãÖ 2 ‚ãÖ 1
                        <br>
                        Por convenci√≥n, 0! = 1.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.4 Permutaciones</td>
                <td>
                    <p>
                        Una permutaci√≥n es un arreglo de todos los elementos de un conjunto donde el orden importa.
                        <br>
                        Sean  <i>n</i>  y  <i>r</i>  n√∫meros naturales no negativos, con <i>r ‚â§ n</i>:
                        <ol type="a">
                            <li>El n√∫mero de permutaciones de  n  objetos distintos es  n! .</li>
                            <li>
                                El n√∫mero de permutaciones de  n  objetos distintos, tomando  r  a la vez, es denotado como:
                                <div id="math-output">
                                    \( _nP_r = \frac{n!}{(n - r)!} \)
                                </div>
                                Esto representa el n√∫mero de maneras de ordenar <i>n</i> elementos seleccionados de un total de <i>r</i> elementos distintos.
                            </li>
                        </ol>
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.5 Combinaciones</td>
                <td>
                    <p>
                        Una combinaci√≥n es un subconjunto no ordenado de tama√±o  <i>r</i>  de un conjunto de  <i>n</i>  objetos distintos.
                        <br>
                        Sean  <i>n</i>  y  <i>r</i>  n√∫meros naturales no negativos, con <i>r ‚â§ n</i>:
                        <ol type="a">
                            <li>
                                El n√∫mero de combinaciones de <i>n</i> objetos distintos tomados <i>r</i> a la vez se denota como:
                                <div id="math-output">
                                    \( _nC_r = \binom{n}{r} = \frac{n!}{r!(n - r)!} \)
                                </div>
                                Esto representa el n√∫mero de maneras de ordenar <i>n</i> elementos seleccionados de un total de <i>r</i> elementos distintos.
                            </li>
                        </ol>
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.6 Diagrama de √Årbol</td>
                <td>
                    <p>
                        Un diagrama de √°rbol se utiliza para visualizar todos los posibles resultados de un experimento o evento, mostrando las
                        ramas correspondientes a cada opci√≥n disponible. Estos permiten representar de manera clara y estructurada eventos simples y
                        compuestos, facilitando el c√°lculo de probabilidades usando el enfoque cl√°sico de casos favorables sobre casos totales.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.7 Teorema del Binomio</td>
                <td>
                    El teorema del binomio establece la expansi√≥n de un binomio elevado a una potencia <i>n</i>.
                    <div id="math-output">
                        \( (a + b)^n = \sum_{k=0}^{n} \binom{n}{k} a^{n-k} b^k \)
                    </div>
                    Donde 
                    <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                        <mrow>
                            <mo>(</mo>
                            <mfrac linethickness="0">
                                <mi>n</mi><mi>k</mi>
                            </mfrac>
                            <mo>)</mo>
                        </mrow>
                    </math>
                    es el coeficiente binomial que representa el n√∫mero de formas de elegir <i>k</i> elementos de un conjunto de <i>n</i> elementos.
                </td>
            </tr>
            <tr>
                <td>2.2 Teor√≠a elemental de probabilidad</td>
                <td>
                    <p>
                        La teor√≠a elemental de probabilidad proporciona herramientas para cuantificar la incertidumbre en eventos aleatorios y sus resultados.<br>
                        Se utiliza para calcular probabilidades simples basadas en el n√∫mero de resultados favorables sobre el n√∫mero total de
                        resultados posibles, especialmente en situaciones donde todos los resultados son igualmente probables. <br>
                        La probabilidad <i>P(A)</i> de un evento <i>A</i> se calcula como el cociente entre los casos
                        favorables para <i>A</i> y los casos totales posibles.
                    </p>
                    <div id="math-output">
                        \( P(A) = \frac{\text{Casos favorables para } A}{\text{Casos totales posibles}} \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>2.3 Probabilidad de Eventos</td>
                <td>
                    <ul>
                        <li><b>Espacio muestral:</b> Conjunto de todos los posibles resultados de un experimento aleatorio.</li>
                        <li><b>Evento:</b> Subconjunto del espacio muestral que representa un resultado espec√≠fico o conjunto de resultados.</li>
                        <li><b>Simbolog√≠a:</b> Utilizaci√≥n de notaciones como <i>P(A)</i> para probabilidad de <i>A</i>‚à™<i>B</i> para uni√≥n de eventos <i>A</i>‚à©<i>B</i> para intersecci√≥n de eventos <i>A</i> y <i>B</i>.</li>
                        <li><b>Operaciones con eventos:</b> Uniones e intersecciones de eventos, representadas visualmente con diagramas de Venn para clarificar relaciones entre eventos.</li>
                        <li><b>Diagramas de Venn:</b> Se utilizan para visualizar las relaciones entre eventos y sus intersecciones dentro del espacio muestral.</li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>2.4 Probabilidad con T√©cnicas de Conteo</td>
                <td>
                    En la teor√≠a de la probabilidad, las t√©cnicas de conteo son utilizadas para determinar el n√∫mero de casos favorables y
                    totales dentro de un espacio muestral, lo cual es crucial para calcular probabilidades. A continuaci√≥n, se detallan
                    aspectos clave de estas t√©cnicas: <br>
                    <b>Axiomas:</b>
                    <ul>
                        <li>
                            <b>No negatividad:</b> La probabilidad de cualquier evento <i>E</i> es un n√∫mero no negativo.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E) \geq 0 \)
                            </div>
                        </li>
                        <li>
                            <b>Normalizaci√≥n:</b> La probabilidad del espacio muestral completo <i>S</i> es igual a 1.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(S) = 1 \)
                            </div>
                        </li>
                        <li>
                            <b>Aditividad:</b> La probabilidad de la uni√≥n de dos eventos mutuamente excluyentes es la suma de las probabilidades de los eventos individuales.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E \cup F) = P(E) + P(F) \quad \text{si } E \cap F = \emptyset \)
                            </div>
                        </li>
                    </ul>
                    <b>Teoremas:</b>
                    <ul>
                        <li>
                            <b>Teorema de la probabilidad condicional:</b>
                            Este teorema calcula la probabilidad de que ocurra el evento <i>E</i> dado que ya ha ocurrido el evento <i>F</i>.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E \mid F) = \frac{P(E \cap F)}{P(F)} \quad \text{si } P(F) > 0 \)
                            </div>
                        </li>
                        <li>
                            <b>Teorema del evento complementario:</b>
                            <i>E<sup>c</sup></i> es el complemento de <i>E</i>, es decir, el evento que no es <i>E</i>.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E^c) = 1 - P(E) \)
                            </div>
                        </li>
                        <li>
                            <b>Regla de multiplicaci√≥n para eventos independientes:</b>
                            Si <i>E</i> y <i>F</i> son eventos independientes, la probabilidad conjunta de ambos eventos es el producto de sus probabilidades individuales.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E \cap F) = P(E) \cdot P(F) \)
                            </div>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>2.5 Probabilidad Condicional</td>
                <td>
                    <ul>
                        <li><b>Dependiente:</b> La probabilidad de que ocurra un evento depende de que otro evento ya haya ocurrido.</li>
                        <li><b>Independiente:</b> La probabilidad de que ocurra un evento no se ve afectada por la ocurrencia o no ocurrencia de otro evento.</li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>2.6 Ley Multiplicativa</td>
                <td>
                    <p>
                        La ley multiplicativa de la probabilidad se refiere a la probabilidad conjunta de dos eventos.
                    </p>
                    <div id="math-output" style="font-size: 1rem;">
                        \( P(E \cap F) = P(E) \cdot P(F \mid E) \)
                    </div>
                    <p>
                        Donde <i>P(E ‚à©F)</i> es la probabilidad de que ocurran ambos eventos <i>P(E)</i> es la probabilidad del evento 
                        <i>E</i>, y <i>P(F |E)</i> es la probabilidad condicional de <i>F</i> dado que <i>E</i> ha ocurrido.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.7 Eventos Independientes: Regla de Bayes</td>
                <td>
                    Cuando dos eventos son independientes, conocer la ocurrencia de uno no proporciona informaci√≥n √∫til sobre la ocurrencia
                    del otro. Por ejemplo, lanzar una moneda dos veces: el resultado del primer lanzamiento no afecta las probabilidades del
                    segundo lanzamiento.
                    <br>
                    Si <i>E</i> y <i>F</i> son independientes, entonces <i>E<sup>c</sup></i>(el complemento de <i>E</i> ) y <i>F</i> tambi√©n son 
                    independientes, y viceversa.
                    <br>
                    M√°s de dos eventos pueden ser independientes simult√°neamente si cada par de eventos es independiente entre s√≠.
                </td>
            </tr>

            <!-- #####################################  TEMA 3 ##################################### -->

            <tr>
                <th colspan="2">
                    <h3>Tema 3: Variables Aleatorias</h3>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>3.1 Variables aleatorias discretas</td>
                <td>
                    <p>
                        Las variables aleatorias discretas son aquellas cuyos valores posibles forman un
                        conjunto finito o infinito numerable. Esto significa que la variable solo puede tomar
                        valores espec√≠ficos, como n√∫meros enteros, y cada uno de estos valores tiene una
                        probabilidad asociada. Por ejemplo, el resultado de lanzar un dado es una variable
                        aleatoria discreta, ya que solo puede tomar valores como 1, 2, 3, 4, 5 o 6, cada uno
                        con una probabilidad espec√≠fica.
                    </p>
                </td>
            </tr>
            <tr>
                <td>3.1.1 Distribuci√≥n de Probabilidad en Forma General</td>
                <td>
                    <p>
                        La distribuci√≥n de probabilidad describe c√≥mo se distribuyen las probabilidades
                        entre los posibles valores que puede tomar una variable aleatoria.
                        <br>
                        Las propiedades que debe cumplir una distribuci√≥n de probabilidad son:
                        <br>
                    </p>
                    <div id="math-output">
                        \( 0 ‚â§ P(Xi) ‚â§ 1 \)
                        <br>
                        \( \sum_{i=1}^{N} P(X_i) = 1 \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.1.2 Valor Esperado</td>
                <td>
                    <p>
                        El valor esperado de una variable aleatoria es el promedio ponderado de todos los
                        posibles valores que puede tomar, ponderados por sus probabilidades respectivas.
                    </p>
                    <div id="math-output">
                        \( \mu = E[X] = \sum_{i=1}^{n} X_i P(X_i) \)
                    </div>
                    <p>
                        Donde <i>X<sub>i</sub></i> son los posibles valores que puede tomar la variable aleatoria
                        <i>X</i>, y <i>P(X<sub>i</sub>)</i> son las probabilidades asociadas a estos valores.
                    </p>
                </td>
            </tr>
            <tr>
                <td>3.1.3 Varianza y Desviaci√≥n Est√°ndar</td>
                <td>
                    <p>
                        La varianza mide la dispersi√≥n de los valores de una variable aleatoria respecto a su media,
                        y se calcula de la siguiente manera:
                    </p>
                    <div id="math-output">
                        $$
                        \begin{align}
                        \sigma^2 &= Var(X) = \sum_{i=1}^{n} P(X_i) (X_i - \mu)^2 \\\\
                        \sigma^2 &= Var(X) = E[X^2] - [E[X]]^2
                        \end{align}
                        $$
                    </div>
                    <br>
                    <p>
                        Mientras que la desviaci√≥n est√°ndar es la ra√≠z cuadrada positiva de la varianza.
                    </p>
                    <div id="math-output">
                        \( \sigma = \sqrt{\sigma^2} = \sqrt{Var(X)} \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.1.4 Funci√≥n de Distribuci√≥n Acumulada (FDA)</td>
                <td>
                    <p>
                        La funci√≥n acumulada (o funci√≥n de distribuci√≥n acumulada) de una variable aleatoria
                        <i>X</i>, denotada como <i>F(x)</i>, indica la probabilidad de que <i>X</i> sea menor
                        o igual a un valor dado <i>x</i>.
                    </p>
                    <div id="math-output">
                        \( F(x) = P(X \leq x) \)
                        <br><br>
                        \( P(X \geq x) + P(X < x)=1 \) <br><br>
                            \( P(X > x) + P(X \leq x) = 1 \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.2 Variables Aleatorias Continuas</td>
                <td>
                    <p>
                        En contraste con las variables aleatorias discretas, las variables aleatorias continuas
                        pueden tomar cualquier valor dentro de un intervalo real. Esto significa que los
                        resultados pueden ser n√∫meros reales y no necesariamente valores espec√≠ficos. <br>
                        Por ejemplo, la altura de una persona o la temperatura medida en grados Celsius son ejemplos
                        de variables aleatorias continuas, ya que pueden tomar cualquier valor dentro de un rango
                        espec√≠fico (por ejemplo, de 0 a 100 cm para la altura, o de -273.15¬∞C a 100¬∞C para la temperatura).
                    </p>
                </td>
            </tr>
            <tr>
                <td>3.2.1 Distribuci√≥n de Probabilidad en Forma General</td>
                <td>
                    <p>
                        La distribuci√≥n de probabilidad para variables aleatorias continuas se describe mediante una
                        funci√≥n de densidad de probabilidad <i>f(x)</i>.
                        <br>
                        Las propiedades que debe cumplir una funci√≥n de densidad son:
                    </p>
                    <div id="math-output">
                        \( f(x) \geq 0 \quad \text{para todo } x \in \mathbb{R} \)
                        <br><br>
                        \( \int\limits_{-\infty}^{\infty} f(x) \, dx = 1 \)
                        <br><br>
                        \( P(a < X < b)=\int\limits_{a}^{b} f(x) \, dx \) 
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.2.2 Valor Esperado</td>
                <td>
                    <p>
                        El valor esperado de una variable aleatoria continua es el promedio ponderado de todos
                        los posibles valores que puede tomar, ponderados por su funci√≥n de densidad de probabilidad.
                    </p>
                    <div id="math-output">
                        \( \mu = E[X] = \int\limits_{-\infty}^{\infty} x f(x) \, dx \)
                    </div>
                </td>
            </tr>
            </tr>
            <tr>
                <td>3.2.3 Varianza y Desviaci√≥n Est√°ndar</td>
                <td>
                    <p>
                        La varianza y la desviaci√≥n est√°ndar de una variable aleatoria continua se calculan de
                        manera similar a las variables discretas, pero integrando respecto a la funci√≥n de
                        densidad de probabilidad.
                    </p>
                    <div id="math-output">
                        $$
                        \begin{align}
                        \sigma^2 &= Var(X) = \int\limits_{-\infty}^{\infty} (x - \mu)^2 f(x) \, dx \\\\
                        \sigma^2 &= Var(X) = E[X^2] - [E[X]]^2
                        \end{align}
                        $$
                    </div>
                    <br>
                    <p>
                        La desviaci√≥n est√°ndar solo es la ra√≠z cuadrada de la varianza.
                    </p>
                    <div id="math-output">
                        \( \sigma = \sqrt{\sigma^2} = \sqrt{Var(X)} \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.2.4 Funci√≥n de Distribuci√≥n Acumulada (FDA)</td>
                <td>
                    <p>
                        La funci√≥n acumulada <i>F(x)</i> de una variable aleatoria continua indica la probabilidad de
                        que
                        la variable aleatoria <i>X</i> sea menor o igual a un valor dado <i>x</i>.
                    </p>
                    <div id="math-output">
                        \( F(x) = P(X \leq x) \)
                    </div>
                    <br>
                    <p>
                        Y la probabilidad de que <i>X</i> est√© en un intervalo [<i>a,b</i>] se calcula como 
                        <i>P</i>(<i>a < X ‚â§ b</i>)<i> = F</i>(<i>b</i>) - F</i>(<i>b</i>).
                    </p>
                </td>
            </tr>
            </tr>
            <tr>
                <td>3.2.5 C√°lculos de Probabilidad</td>
                <td>
                    Los c√°lculos de probabilidad para variables aleatorias continuas se realizan principalmente mediante
                    integrales de la funci√≥n de densidad de probabilidad (PDF) en intervalos espec√≠ficos, como se
                    indic√≥ anteriormente.
                </td>
            </tr>

            <!-- #####################################  TEMA 4 ##################################### -->

            <tr>
                <th colspan="2">
                    <h3>Tema 4: Distribuciones de Probabilidad</h3>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>4.1 Funci√≥n de probabilidad</td>
                <td>
                    <p>
                        Se define como una funci√≥n que asigna probabilidades a cada valor posible de la variable.
                        La funci√≥n de probabilidad asigna la probabilidad de que una variable aleatoria discreta
                        <i>X</i> tome un valor espec√≠fico <i>x</i>.
                    </p>
                    <div id="math-output">
                        \( P(X = x) \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>4.2 Distribuci√≥n binomial</td>
                <td>
                    <p>
                        La distribuci√≥n binomial se utiliza para modelar la probabilidad de obtener un n√∫mero
                        espec√≠fico de √©xitos en un n√∫mero fijo de ensayos de Bernoulli con dos resultados posibles,
                        cada uno con la misma probabilidad de √©xito (<i>p</i>).
                        <br>
                        F√≥rmula de la funci√≥n de probabilidad:
                    </p>
                    <div id="math-output">
                        \( P(k; n, p) = \binom{n}{k} p^k (1 - p)^{n - k} \)
                    </div>
                    <p>
                        Donde <i>n</i> es el n√∫mero de ensayos de Bernoulli, <i>k</i> es el n√∫mero de √©xitos, y <i>p</i>
                        es la probabilidad de √©xito en un ensayo.
                        <br>
                        C√°lculo de la media:
                    <div id="math-output">
                        \( np \)
                    </div>
                    C√°lculo de la varianza:
                    <div id="math-output">
                        \( np(1 - p) \)
                    </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import binom

n = 10
p = 0.5
k=4
prob = binom.pmf(k, n, p)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.3 Distribuci√≥n hipergeom√©trica</td>
                <td>
                    <p>
                        La distribuci√≥n hipergeom√©trica modela la probabilidad de obtener un n√∫mero espec√≠fico
                        de elementos de inter√©s (√©xitos) en una muestra extra√≠da sin reemplazo de una poblaci√≥n
                        finita dividida en dos grupos.
                        <br>
                        F√≥rmula de la funci√≥n de probabilidad:
                    </p>
                    <div id="math-output">
                        \( P(k; N, n, K) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}} \)
                    </div>
                    <p>
                        Donde <i>N</i> es el tama√±o total de la poblaci√≥n, <i>K</i> es el n√∫mero de elementos de inter√©s
                        en la poblaci√≥n,
                        <i>n</i> es el tama√±o de la muestra y <i>k</i> es el n√∫mero de √©xitos en la muestra.
                        <br>
                        C√°lculo de la media:
                        <div id="math-output">
                            \( \frac{nK}{N} \)
                        </div>
                        C√°lculo de la varianza:
                        <div id="math-output">
                            \( \frac{nK (N-K)(N-n)}{N^2(N-1)} \)
                        </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import hypergeom
N = 100
n = 20
K = 10
k=4
prob = hypergeom.pmf(k, N, n, K)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.4 Distribuci√≥n de Poisson</td>
                <td>
                    <p>
                        La distribuci√≥n de Poisson se utiliza para modelar el n√∫mero de eventos de baja frecuencia
                        (eventos raros)
                        que ocurren en un intervalo de tiempo o espacio.
                        <br>
                        F√≥rmula de la funci√≥n de probabilidad:
                    </p>
                    <div id="math-output">
                        \( P(k; \lambda) = \frac{e^{-\lambda} \lambda^k}{k!} \)
                    </div>
                    <p>
                        Donde Œª es el n√∫mero promedio de eventos por intervalo de tiempo o espacio, y <i>k</i> es el
                        n√∫mero de
                        eventos que queremos modelar.
                        <br>
                        C√°lculo de la media:
                        <div id="math-output">
                            \( \lambda \)
                        </div>
                        C√°lculo de la varianza:
                        <div id="math-output">
                            \( \lambda \)
                        </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import poisson
lmbda = 3
k=2
prob = poisson.pmf(k, lmbda)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.5 Distribuci√≥n normal</td>
                <td>
                    <p>
                        La distribuci√≥n normal es utilizada para modelar una amplia variedad de fen√≥menos naturales y
                        sociales
                        debido a su forma de campana y propiedades estad√≠sticas bien conocidas.
                        <br>
                        Funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(x; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x - \mu)^2}{2 \sigma^2}} \)
                    </div>
                    <p>
                        Donde ùúá es la media y œÉ<sup>2</sup> es la varianza de la distribuci√≥n.
                        <br>
                        C√°lculo de la media:
                        <div id="math-output">
                            \( \mu \)
                        </div>
                        C√°lculo de la varianza:
                        <div id="math-output">
                            \( \sigma^2 \)
                        </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import norm
mu = 0
sigma = 1
x = 1.5
prob = norm.pdf(x, mu, sigma)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.6 Distribuci√≥n T-student</td>
                <td>
                    <p>
                        La distribuci√≥n T-student se utiliza para inferencia estad√≠stica cuando el tama√±o de la
                        muestra es peque√±o y la varianza de la poblaci√≥n es desconocida.
                        <br>
                        F√≥rmula de la funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(t | \nu) = \frac{\Gamma\left(\frac{\nu + 1}{2}\right)}{\sqrt{\nu \pi} \Gamma\left(\frac{\nu}{2}\right) \left(1 + \frac{t^2}{\nu}\right)^{\frac{\nu + 1}{2}}} \)
                    </div>
                    <p>
                        Donde <i>t</i> es la variable aleatoria T de Student, <i>v</i> son los grados de libertad de la
                        distribuci√≥n
                        y <i>Œì</i>(‚ãÖ) denota la funci√≥n gamma, que para un entero <i>n</i> es (<i>n</i>-1)!.
                    </p>
                </td>
            </tr>
            <tr>
                <td>4.7 Distribuci√≥n Chi cuadrada</td>
                <td>
                    <p>
                        La distribuci√≥n Chi cuadrada se utiliza para pruebas de hip√≥tesis y para construir intervalos de
                        confianza
                        sobre la varianza de una poblaci√≥n normalmente distribuida.
                        <br>
                        Funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(x | \nu) = \frac{x^{\frac{\nu}{2} - 1} e^{-\frac{x}{2}}}{2^{\frac{\nu}{2}}
                        \Gamma\left(\frac{\nu}{2}\right)} \)
                    </div>
                    <p>
                        Donde <i>x</i> es la variable aleatoria Chi-cuadrado, <i>v</i> es el n√∫mero de grados de
                        libertad y <i>Œì</i>(‚ãÖ) denota la funci√≥n gamma.
                    </p>
                </td>
            </tr>
            <tr>
                <td>4.8 Distribuci√≥n F</td>
                <td>
                    <p>
                        La distribuci√≥n F se utiliza principalmente en an√°lisis de varianza (ANOVA) y en
                        comparaciones de varianzas entre dos o m√°s muestras.
                        <br>
                        Funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(x | d_1, d_2) = \frac{\Gamma\left(\frac{d_1 + d_2}{2}\right) \left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}} x^{\frac{d_1}{2} - 1}}{\Gamma\left(\frac{d_1}{2}\right) \Gamma\left(\frac{d_2}{2}\right) \left(1 + \frac{d_1 x}{d_2}\right)^{\frac{d_1 + d_2}{2}}} \)
                    </div>
                    <p>
                        Donde donde <i>d</i><sub>1</sub> y <i>d</i><sub>2</sub> son los grados de libertad de las dos muestras que se est√°n
                        comparando.
                    </p>
                </td>
            </tr>
        </table>
    </div>

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>