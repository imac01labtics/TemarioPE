<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Temario Probabilidad y Estad√≠stica</title>
    <!-- Recursos -->
    <link rel="icon" href="img/icon.ico" type="image/x-icon">
    <link rel="stylesheet" href="style.css">
    <!-- MathJax permite renderizar formato LaTeX -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <!-- Incluir la fuente de KaTeX -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
    <!-- Include Highlight.js CSS for Monokai theme -->
    <link rel="stylesheet"
        href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/styles/stackoverflow-light.min.css">
</head>

<body>
    <div>
        <table id="main-table" style="width: 90%;">
            <!-- #####################################  TEMA 1 ##################################### -->

            <tr>
                <th colspan="2">
                    <h2>Tema 1: Estad√≠stica descriptiva</h2>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>1.1 Conceptos b√°sicos de estad√≠stica</td>
                <td>
                    <p>
                        <b>Definici√≥n de estad√≠stica:</b> La estad√≠stica es una rama de las matem√°ticas que se ocupa de la recopilaci√≥n, an√°lisis, interpretaci√≥n y presentaci√≥n de datos. Su objetivo es describir patrones y tendencias en conjuntos de datos para hacer inferencias y tomar decisiones.<br>
                        <b>Teor√≠a de decisi√≥n:</b> Es un √°rea de la estad√≠stica que estudia c√≥mo tomar decisiones √≥ptimas bajo incertidumbre, utilizando herramientas estad√≠sticas y probabil√≠sticas para evaluar diferentes opciones y sus consecuencias.<br>
                        <b>Poblaci√≥n:</b> En estad√≠stica, una poblaci√≥n se refiere al conjunto completo de elementos o individuos que tienen al menos una caracter√≠stica en com√∫n y que son de inter√©s para el estudio estad√≠stico.<br>
                        <b>Muestra aleatoria:</b> Es un subconjunto representativo de la poblaci√≥n elegido de manera que cada miembro de la poblaci√≥n tenga la misma probabilidad de ser seleccionado. Las muestras aleatorias son fundamentales para generalizar conclusiones sobre la poblaci√≥n m√°s amplia a partir de los datos recogidos.<br>
                        <b>Par√°metros aleatorios:</b> Son caracter√≠sticas num√©ricas que describen una poblaci√≥n completa y que generalmente son desconocidas. Por ejemplo, la media poblacional, la desviaci√≥n est√°ndar, etc. Estos par√°metros son inferidos a partir de la informaci√≥n obtenida de una muestra.
                    </p>
                </td>
            </tr>
            <tr>
                <td>1.2 Descripci√≥n de datos</td>
                <td>
                    <p>
                        <b>Datos no agrupados:</b> Son datos individuales que se presentan tal como se recopilan, sin clasificar en categor√≠as o intervalos. Cada observaci√≥n tiene un valor espec√≠fico y √∫nico. <br>
                        <b>Datos agrupados:</b> Son datos que se organizan en intervalos o clases para resumir la informaci√≥n y facilitar su an√°lisis. En lugar de listar cada valor individual, los datos se agrupan en rangos o clases. <br>
                        <b>Frecuencia de clase:</b> En datos agrupados, la frecuencia de clase se refiere al n√∫mero de observaciones que caen dentro de cada intervalo o clase. Es decir, cu√°ntas veces aparece un valor dentro de un intervalo espec√≠fico. <br>
                        <b>Frecuencia relativa:</b> Es la proporci√≥n o el porcentaje de observaciones que caen dentro de cada clase en relaci√≥n con el n√∫mero total de observaciones. Se calcula dividiendo la frecuencia de clase entre el tama√±o total de la muestra. <br>
                        <b>Punto medio de clase:</b> En datos agrupados, el punto medio de clase es el valor medio de cada intervalo o clase. Se calcula sumando los l√≠mites inferior y superior de la clase y dividiendo por 2. <br>
                        <b>L√≠mites de clase:</b> Son los valores que definen los extremos de cada intervalo o clase en datos agrupados. Existen l√≠mites inferior y superior para cada intervalo, que determinan los valores m√≠nimos y m√°ximos dentro de ese rango. <br>
                    </p>
                </td>
            </tr>
            <tr>
                <td>1.3 Medidas de tendencia central y Medidas de dispersi√≥n</td>
                <td>
                    <p>
                        <b>Medidas de tendencia central:</b> <br>
                        Media aritm√©tica: Es el promedio de un conjunto de datos num√©ricos. Se calcula sumando todos los valores y dividiendo por el n√∫mero total de observaciones n.
                        <div id="math-output">
                            \( \bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i \)
                        </div>
                        Media geom√©trica: Es √∫til para calcular el promedio de tasas de crecimiento o cuando se manejan datos que crecen exponencialmente. Se obtiene calculando la ra√≠z en√©sima del producto de los valores.
                        <div id="math-output">
                            \( \bar{x}_{geom} = \left( \prod_{i=1}^{n} x_i \right)^{1/n} \)
                        </div>
                        Media ponderada: Es la media en la cual diferentes observaciones tienen pesos diferentes. Se calcula multiplicando cada valor por su peso correspondiente, sumando estos productos y dividiendo por la suma de los pesos.
                        <div id="math-output">
                            \( \bar{x}_{pond} = \frac{\sum_{i=1}^{n} w_i \cdot x_i}{\sum_{i=1}^{n} w_i} \)
                        </div>
                        Mediana: Es el valor que separa a la mitad de los datos cuando estos est√°n ordenados de menor a mayor (o viceversa). Si n es impar, la mediana es el valor en el centro de la distribuci√≥n; si n es par, es el promedio de los dos valores centrales.
                        <br>
                        Moda: Es el valor que ocurre con mayor frecuencia en un conjunto de datos. Puede haber una moda (unimodal), dos modas (bimodal) o m√°s (multimodal).
                        <br>
                        <b>Medidas de dispersi√≥n:</b> <br>
                        Varianza: Mide la dispersi√≥n de los datos con respecto a la media. Se calcula como la media de los cuadrados de las desviaciones de cada valor respecto a la media.
                        <div id="math-output">
                            \( \sigma^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2 \)
                        </div>
                        Desviaci√≥n est√°ndar: Es la ra√≠z cuadrada positiva de la varianza y proporciona una medida de dispersi√≥n m√°s intuitiva en la misma escala de los datos originales.
                        <div id="math-output">
                            \( \sigma = \sqrt{\sigma^2} \)
                        </div>
                        <br>
                        Desviaci√≥n media: Es la media de las desviaciones absolutas de cada valor respecto a la media.
                        <div id="math-output">
                            \( \text{Desviaci√≥n media} = \frac{1}{n} \sum_{i=1}^{n} |x_i - \bar{x}| \)
                        </div>
                        Desviaci√≥n mediana: Es la mediana de las desviaciones absolutas de cada valor respecto a la mediana.
                        <br>
                        Rango: Es la diferencia entre el valor m√°ximo y el valor m√≠nimo en un conjunto de datos. Proporciona una medida simple de la amplitud de los datos.
                        <div id="math-output">
                            \( \text{Rango} = x_{\max} - x_{\min} \)
                        </div>
                    </p>
                </td>
            </tr>
            <tr>
                <td>1.4 Par√°metros para datos agrupados</td>
                <td>
                    <p>
                        En estad√≠stica, cuando los datos est√°n agrupados en intervalos o clases, se utilizan diferentes par√°metros para
                        caracterizar la distribuci√≥n de los datos de manera resumida: <br>
                    </p>
                    <ul>
                        <li>
                            <b>Media para datos agrupados:</b> Es el promedio ponderado de los puntos medios de cada clase, utilizando las frecuencias 
                            como pesos. <br>
                            <div id="math-output">
                                \( \bar{x} = \frac{\sum_{i=1}^{k} f_i \cdot x_i}{n} \)
                            </div>
                            Donde <i>k</i> es el n√∫mero de clases, <i>F<sub>i</sub></i> es la frecuencia de la i-√©sima clase, <i>x<sub>i</sub></i> 
                            es el punto medio de la i-√©sima clase, y <i>n</i> es el n√∫mero total de observaciones.
                        </li>
                        <li>
                            <b>Varianza y desviaci√≥n est√°ndar para datos agrupados:</b> Son medidas de dispersi√≥n ajustadas para datos agrupados, 
                            calculadas utilizando las frecuencias y los puntos medios de las clases.
                            <div id="math-output">
                                \( \sigma^2 = \frac{\sum_{i=1}^{k} f_i \cdot (x_i - \bar{x})^2}{n} \)
                                <br>
                                \( \sigma = \sqrt{\sigma^2} \)
                            </div>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>1.5 Distribuci√≥n de frecuencias</td>
                <td>
                    <p>
                        La distribuci√≥n de frecuencias es una tabla que muestra la frecuencia (n√∫mero de veces) con la que ocurren diferentes
                        valores o rangos de valores en un conjunto de datos. Incluye:
                    </p>
                    <ul>
                        <li><b>Frecuencia absoluta <i>(f)</i></b>: N√∫mero de veces que un valor espec√≠fico o un intervalo de valores ocurre en el conjunto de datos.</li>
                        <li><b>Frecuencia relativa <i>(fr)</i></b>: Proporci√≥n de la frecuencia absoluta respecto al total de observaciones.</li>
                        <li><b>Frecuencia acumulada <i>(F)</i></b>: Suma acumulativa de las frecuencias absolutas hasta una clase espec√≠fica.</li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>1.6 T√©cnicas de agrupaci√≥n de datos</td>
                <td>
                    <p>
                        Agrupar datos implica organizar los datos en clases o intervalos para facilitar su an√°lisis y presentaci√≥n. Las t√©cnicas comunes incluyen:                
                    </p>
                    <ul>
                        <li><b>Determinaci√≥n del rango y n√∫mero de clases:</b> Se calcula el rango de los datos y se decide el n√∫mero de clases.</li>
                        <li><b>Amplitud de clase:</b> La amplitud de cada clase se determina dividiendo el rango por el n√∫mero de clases.</li>
                        <li><b>L√≠mites de clase</b>: Se establecen los l√≠mites inferior y superior de cada clase.</li>
                        <li><b>Punto medio de clase:</b> Se calcula como el promedio de los l√≠mites inferior y superior de la clase.</li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>1.7 T√©cnicas de muestreo</td>
                <td>
                    <p>Las t√©cnicas de muestreo son m√©todos utilizados para seleccionar una muestra representativa de una poblaci√≥n m√°s amplia. Incluyen: </p>
                    <ul>
                        <li><b>Muestreo aleatorio simple:</b> Cada miembro de la poblaci√≥n tiene la misma probabilidad de ser seleccionado.</li>
                        <li><b>Muestreo estratificado:</b> La poblaci√≥n se divide en subgrupos (estratos) y se toma una muestra aleatoria de cada uno.</li>
                        <li><b>Muestreo sistem√°tico:</b> Se selecciona cada <i>k</i>-√©simo miembro de la poblaci√≥n.</li>
                        <li><b>Muestreo por conglomerados:</b> La poblaci√≥n se divide en grupos (conglomerados) y se seleccionan aleatoriamente algunos de estos grupos.</li>
                    </ul>
                    <p>Estas t√©cnicas aseguran que la muestra sea representativa de la poblaci√≥n, permitiendo inferencias v√°lidas y precisas sobre la poblaci√≥n completa.</p>
                </td>
            </tr>
            <tr>
                <td>1.8 Histogramas</td>
                <td>
                    <p>
                        Un histograma es una representaci√≥n gr√°fica que muestra la distribuci√≥n de frecuencias de datos continuos. Se utiliza
                        para visualizar la forma y la distribuci√≥n de un conjunto de datos, destacando qu√© intervalos o clases tienen mayor
                        concentraci√≥n de datos. <br>
                        Para crear un histograma, se siguen estos pasos:
                    </p>
                    <ul>
                        <li><b>Dibujo de los ejes coordenados:</b> Se dibujan los ejes x e y. El eje x representa las clases o intervalos de datos, y el eje y representa la frecuencia de cada clase.</li>
                        <li><b>Marcas en el eje x:</b> Se colocan las marcas correspondientes a cada clase o intervalo de datos en el eje x. Cada columna del histograma representa un intervalo de clase, por lo que la base de cada columna debe coincidir con el ancho del intervalo de clase.</li>
                        <li><b>Altura de las columnas:</b> En el eje y se representa la frecuencia absoluta o relativa de cada clase. La altura de cada columna del histograma corresponde a esta frecuencia.</li>
                    </ul>
                </td>
            </tr>

            <!-- #####################################  TEMA 2 ##################################### -->

            <tr>
                <th colspan="2">
                    <h2>Tema 2: Fundamentos de la Teor√≠a de Probabilidad</h2>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>2.1 T√©cnicas de Conteo</td>
                <td>
                    <p>
                        Las t√©cnicas de conteo son m√©todos utilizados para determinar el n√∫mero de posibles resultados o eventos en un conjunto
                        dado. Estas t√©cnicas son fundamentales en la teor√≠a de probabilidad para calcular probabilidades y analizar eventos
                        complejos. Incluyen la notaci√≥n factorial, los principios multiplicativo y aditivo, permutaciones, combinaciones y el
                        uso de diagramas de √°rbol.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.1 Principio aditivo</td>
                <td>
                    <p>
                        El principio aditivo establece que si dos operaciones son mutuamente excluyentes (no pueden ocurrir simult√°neamente),
                        entonces el n√∫mero total de formas en que se pueden realizar ambas operaciones es la suma de las formas individuales.
                        <br>
                        Si una operaci√≥n puede realizarse en m formas y otra en n y ambas no pueden realizarse juntas, entonces el n√∫mero total 
                        de formas en las que se pueden realizar es <i>m + n</i>.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.2 Principio Multiplicativo</td>
                <td>
                    <p>
                        El principio multiplicativo indica que si una operaci√≥n puede realizarse de <i>m</i> formas y otra operaci√≥n de <i>n</i>
                        formas, entonces ambas operaciones pueden realizarse juntas de <i>m ‚ãÖ n</i> formas.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.3 Notaci√≥n Factorial</td>
                <td>
                    <p>
                        La notaci√≥n factorial se utiliza para representar el producto de todos los enteros positivos hasta un n√∫mero dado <i>n</i>.
                        <br>
                        <i>n</i>! = <i>n</i> ‚ãÖ (<i>n</i> - 1) ‚ãÖ (<i>n</i> - 2) ‚ãÖ ... ‚ãÖ 3 ‚ãÖ 2 ‚ãÖ 1
                        <br>
                        Por convenci√≥n, 0! = 1.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.4 Permutaciones</td>
                <td>
                    <p>
                        Una permutaci√≥n es un arreglo de todos los elementos de un conjunto donde el orden importa.
                        <br>
                        Sean  <i>n</i>  y  <i>r</i>  n√∫meros naturales no negativos, con <i>r ‚â§ n</i>:
                        <ol type="a">
                            <li>El n√∫mero de permutaciones de  n  objetos distintos es  n! .</li>
                            <li>
                                El n√∫mero de permutaciones de  n  objetos distintos, tomando  r  a la vez, es denotado como:
                                <div id="math-output">
                                    \( _nP_r = \frac{n!}{(n - r)!} \)
                                </div>
                                Esto representa el n√∫mero de maneras de ordenar <i>n</i> elementos seleccionados de un total de <i>r</i> elementos distintos.
                            </li>
                        </ol>
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.5 Combinaciones</td>
                <td>
                    <p>
                        Una combinaci√≥n es un subconjunto no ordenado de tama√±o  <i>r</i>  de un conjunto de  <i>n</i>  objetos distintos.
                        <br>
                        Sean  <i>n</i>  y  <i>r</i>  n√∫meros naturales no negativos, con <i>r ‚â§ n</i>:
                        <ol type="a">
                            <li>
                                El n√∫mero de combinaciones de <i>n</i> objetos distintos tomados <i>r</i> a la vez se denota como:
                                <div id="math-output">
                                    \( _nC_r = \binom{n}{r} = \frac{n!}{r!(n - r)!} \)
                                </div>
                                Esto representa el n√∫mero de maneras de ordenar <i>n</i> elementos seleccionados de un total de <i>r</i> elementos distintos.
                            </li>
                        </ol>
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.6 Diagrama de √Årbol</td>
                <td>
                    <p>
                        Un diagrama de √°rbol se utiliza para visualizar todos los posibles resultados de un experimento o evento, mostrando las
                        ramas correspondientes a cada opci√≥n disponible. Estos permiten representar de manera clara y estructurada eventos simples y
                        compuestos, facilitando el c√°lculo de probabilidades usando el enfoque cl√°sico de casos favorables sobre casos totales.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.1.7 Teorema del Binomio</td>
                <td>
                    El teorema del binomio establece la expansi√≥n de un binomio elevado a una potencia <i>n</i>.
                    <div id="math-output">
                        \( (a + b)^n = \sum_{k=0}^{n} \binom{n}{k} a^{n-k} b^k \)
                    </div>
                    Donde 
                    <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                        <mrow>
                            <mo>(</mo>
                            <mfrac linethickness="0">
                                <mi>n</mi><mi>k</mi>
                            </mfrac>
                            <mo>)</mo>
                        </mrow>
                    </math>
                    es el coeficiente binomial que representa el n√∫mero de formas de elegir <i>k</i> elementos de un conjunto de <i>n</i> elementos.
                </td>
            </tr>
            <tr>
                <td>2.2 Teor√≠a elemental de probabilidad</td>
                <td>
                    <p>
                        La teor√≠a elemental de probabilidad proporciona herramientas para cuantificar la incertidumbre en eventos aleatorios y sus resultados.<br>
                        Se utiliza para calcular probabilidades simples basadas en el n√∫mero de resultados favorables sobre el n√∫mero total de
                        resultados posibles, especialmente en situaciones donde todos los resultados son igualmente probables. <br>
                        La probabilidad <i>P(A)</i> de un evento <i>A</i> se calcula como el cociente entre los casos
                        favorables para <i>A</i> y los casos totales posibles.
                    </p>
                    <div id="math-output">
                        \( P(A) = \frac{\text{Casos favorables para } A}{\text{Casos totales posibles}} \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>2.3 Probabilidad de Eventos</td>
                <td>
                    <ul>
                        <li><b>Espacio muestral:</b> Conjunto de todos los posibles resultados de un experimento aleatorio.</li>
                        <li><b>Evento:</b> Subconjunto del espacio muestral que representa un resultado espec√≠fico o conjunto de resultados.</li>
                        <li><b>Simbolog√≠a:</b> Utilizaci√≥n de notaciones como <i>P(A)</i> para probabilidad de <i>A</i>‚à™<i>B</i> para uni√≥n de eventos <i>A</i>‚à©<i>B</i> para intersecci√≥n de eventos <i>A</i> y <i>B</i>.</li>
                        <li><b>Operaciones con eventos:</b> Uniones e intersecciones de eventos, representadas visualmente con diagramas de Venn para clarificar relaciones entre eventos.</li>
                        <li><b>Diagramas de Venn:</b> Se utilizan para visualizar las relaciones entre eventos y sus intersecciones dentro del espacio muestral.</li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>2.4 Probabilidad con T√©cnicas de Conteo</td>
                <td>
                    En la teor√≠a de la probabilidad, las t√©cnicas de conteo son utilizadas para determinar el n√∫mero de casos favorables y
                    totales dentro de un espacio muestral, lo cual es crucial para calcular probabilidades. A continuaci√≥n, se detallan
                    aspectos clave de estas t√©cnicas: <br>
                    <b>Axiomas:</b>
                    <ul>
                        <li>
                            <b>No negatividad:</b> La probabilidad de cualquier evento <i>E</i> es un n√∫mero no negativo.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E) \geq 0 \)
                            </div>
                        </li>
                        <li>
                            <b>Normalizaci√≥n:</b> La probabilidad del espacio muestral completo <i>S</i> es igual a 1.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(S) = 1 \)
                            </div>
                        </li>
                        <li>
                            <b>Aditividad:</b> La probabilidad de la uni√≥n de dos eventos mutuamente excluyentes es la suma de las probabilidades de los eventos individuales.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E \cup F) = P(E) + P(F) \quad \text{si } E \cap F = \emptyset \)
                            </div>
                        </li>
                    </ul>
                    <b>Teoremas:</b>
                    <ul>
                        <li>
                            <b>Teorema de la probabilidad condicional:</b>
                            Este teorema calcula la probabilidad de que ocurra el evento <i>E</i> dado que ya ha ocurrido el evento <i>F</i>.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E \mid F) = \frac{P(E \cap F)}{P(F)} \quad \text{si } P(F) > 0 \)
                            </div>
                        </li>
                        <li>
                            <b>Teorema del evento complementario:</b>
                            <i>E<sup>c</sup></i> es el complemento de <i>E</i>, es decir, el evento que no es <i>E</i>.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E^c) = 1 - P(E) \)
                            </div>
                        </li>
                        <li>
                            <b>Regla de multiplicaci√≥n para eventos independientes:</b>
                            Si <i>E</i> y <i>F</i> son eventos independientes, la probabilidad conjunta de ambos eventos es el producto de sus probabilidades individuales.
                            <div id="math-output" style="font-size: 1rem;">
                                \( P(E \cap F) = P(E) \cdot P(F) \)
                            </div>
                        </li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>2.5 Probabilidad Condicional</td>
                <td>
                    <ul>
                        <li><b>Dependiente:</b> La probabilidad de que ocurra un evento depende de que otro evento ya haya ocurrido.</li>
                        <li><b>Independiente:</b> La probabilidad de que ocurra un evento no se ve afectada por la ocurrencia o no ocurrencia de otro evento.</li>
                    </ul>
                </td>
            </tr>
            <tr>
                <td>2.6 Ley Multiplicativa</td>
                <td>
                    <p>
                        La ley multiplicativa de la probabilidad se refiere a la probabilidad conjunta de dos eventos.
                    </p>
                    <div id="math-output" style="font-size: 1rem;">
                        \( P(E \cap F) = P(E) \cdot P(F \mid E) \)
                    </div>
                    <p>
                        Donde <i>P(E ‚à©F)</i> es la probabilidad de que ocurran ambos eventos <i>P(E)</i> es la probabilidad del evento 
                        <i>E</i>, y <i>P(F |E)</i> es la probabilidad condicional de <i>F</i> dado que <i>E</i> ha ocurrido.
                    </p>
                </td>
            </tr>
            <tr>
                <td>2.7 Eventos Independientes: Regla de Bayes</td>
                <td>
                    Cuando dos eventos son independientes, conocer la ocurrencia de uno no proporciona informaci√≥n √∫til sobre la ocurrencia
                    del otro. Por ejemplo, lanzar una moneda dos veces: el resultado del primer lanzamiento no afecta las probabilidades del
                    segundo lanzamiento.
                    <br>
                    Si <i>E</i> y <i>F</i> son independientes, entonces <i>E<sup>c</sup></i>(el complemento de <i>E</i> ) y <i>F</i> tambi√©n son 
                    independientes, y viceversa.
                    <br>
                    M√°s de dos eventos pueden ser independientes simult√°neamente si cada par de eventos es independiente entre s√≠.
                </td>
            </tr>

            <!-- #####################################  TEMA 3 ##################################### -->

            <tr>
                <th colspan="2">
                    <h2>Tema 3: Variables Aleatorias</h2>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>3.1 Variables aleatorias discretas</td>
                <td>
                    <p>
                        Las variables aleatorias discretas son aquellas cuyos valores posibles forman un
                        conjunto finito o infinito numerable. Esto significa que la variable solo puede tomar
                        valores espec√≠ficos, como n√∫meros enteros, y cada uno de estos valores tiene una
                        probabilidad asociada. Por ejemplo, el resultado de lanzar un dado es una variable
                        aleatoria discreta, ya que solo puede tomar valores como 1, 2, 3, 4, 5 o 6, cada uno
                        con una probabilidad espec√≠fica.
                    </p>
                </td>
            </tr>
            <tr>
                <td>3.1.1 Distribuci√≥n de Probabilidad en Forma General</td>
                <td>
                    <p>
                        La distribuci√≥n de probabilidad describe c√≥mo se distribuyen las probabilidades
                        entre los posibles valores que puede tomar una variable aleatoria.
                        <br>
                        Las propiedades que debe cumplir una distribuci√≥n de probabilidad son:
                        <br>
                    </p>
                    <div id="math-output">
                        \( 0 ‚â§ P(Xi) ‚â§ 1 \)
                        <br>
                        \( \sum_{i=1}^{N} P(X_i) = 1 \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.1.2 Valor Esperado</td>
                <td>
                    <p>
                        El valor esperado de una variable aleatoria es el promedio ponderado de todos los
                        posibles valores que puede tomar, ponderados por sus probabilidades respectivas.
                    </p>
                    <div id="math-output">
                        \( \mu = E[X] = \sum_{i=1}^{n} X_i P(X_i) \)
                    </div>
                    <p>
                        Donde <i>X<sub>i</sub></i> son los posibles valores que puede tomar la variable aleatoria
                        <i>X</i>, y <i>P(X<sub>i</sub>)</i> son las probabilidades asociadas a estos valores.
                    </p>
                </td>
            </tr>
            <tr>
                <td>3.1.3 Varianza y Desviaci√≥n Est√°ndar</td>
                <td>
                    <p>
                        La varianza mide la dispersi√≥n de los valores de una variable aleatoria respecto a su media,
                        y se calcula de la siguiente manera:
                    </p>
                    <div id="math-output">
                        $$
                        \begin{align}
                        \sigma^2 &= Var(X) = \sum_{i=1}^{n} P(X_i) (X_i - \mu)^2 \\\\
                        \sigma^2 &= Var(X) = E[X^2] - [E[X]]^2
                        \end{align}
                        $$
                    </div>
                    <br>
                    <p>
                        Mientras que la desviaci√≥n est√°ndar es la ra√≠z cuadrada positiva de la varianza.
                    </p>
                    <div id="math-output">
                        \( \sigma = \sqrt{\sigma^2} = \sqrt{Var(X)} \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.1.4 Funci√≥n de Distribuci√≥n Acumulada (FDA)</td>
                <td>
                    <p>
                        La funci√≥n acumulada (o funci√≥n de distribuci√≥n acumulada) de una variable aleatoria
                        <i>X</i>, denotada como <i>F(x)</i>, indica la probabilidad de que <i>X</i> sea menor
                        o igual a un valor dado <i>x</i>.
                    </p>
                    <div id="math-output">
                        \( F(x) = P(X \leq x) \)
                        <br><br>
                        \( P(X \geq x) + P(X < x)=1 \) <br><br>
                            \( P(X > x) + P(X \leq x) = 1 \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.2 Variables Aleatorias Continuas</td>
                <td>
                    <p>
                        En contraste con las variables aleatorias discretas, las variables aleatorias continuas
                        pueden tomar cualquier valor dentro de un intervalo real. Esto significa que los
                        resultados pueden ser n√∫meros reales y no necesariamente valores espec√≠ficos. <br>
                        Por ejemplo, la altura de una persona o la temperatura medida en grados Celsius son ejemplos
                        de variables aleatorias continuas, ya que pueden tomar cualquier valor dentro de un rango
                        espec√≠fico (por ejemplo, de 0 a 100 cm para la altura, o de -273.15¬∞C a 100¬∞C para la temperatura).
                    </p>
                </td>
            </tr>
            <tr>
                <td>3.2.1 Distribuci√≥n de Probabilidad en Forma General</td>
                <td>
                    <p>
                        La distribuci√≥n de probabilidad para variables aleatorias continuas se describe mediante una
                        funci√≥n de densidad de probabilidad <i>f(x)</i>.
                        <br>
                        Las propiedades que debe cumplir una funci√≥n de densidad son:
                    </p>
                    <div id="math-output">
                        \( f(x) \geq 0 \quad \text{para todo } x \in \mathbb{R} \)
                        <br><br>
                        \( \int\limits_{-\infty}^{\infty} f(x) \, dx = 1 \)
                        <br><br>
                        \( P(a < X < b)=\int\limits_{a}^{b} f(x) \, dx \) 
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.2.2 Valor Esperado</td>
                <td>
                    <p>
                        El valor esperado de una variable aleatoria continua es el promedio ponderado de todos
                        los posibles valores que puede tomar, ponderados por su funci√≥n de densidad de probabilidad.
                    </p>
                    <div id="math-output">
                        \( \mu = E[X] = \int\limits_{-\infty}^{\infty} x f(x) \, dx \)
                    </div>
                </td>
            </tr>
            </tr>
            <tr>
                <td>3.2.3 Varianza y Desviaci√≥n Est√°ndar</td>
                <td>
                    <p>
                        La varianza y la desviaci√≥n est√°ndar de una variable aleatoria continua se calculan de
                        manera similar a las variables discretas, pero integrando respecto a la funci√≥n de
                        densidad de probabilidad.
                    </p>
                    <div id="math-output">
                        $$
                        \begin{align}
                        \sigma^2 &= Var(X) = \int\limits_{-\infty}^{\infty} (x - \mu)^2 f(x) \, dx \\\\
                        \sigma^2 &= Var(X) = E[X^2] - [E[X]]^2
                        \end{align}
                        $$
                    </div>
                    <br>
                    <p>
                        La desviaci√≥n est√°ndar solo es la ra√≠z cuadrada de la varianza.
                    </p>
                    <div id="math-output">
                        \( \sigma = \sqrt{\sigma^2} = \sqrt{Var(X)} \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>3.2.4 Funci√≥n de Distribuci√≥n Acumulada (FDA)</td>
                <td>
                    <p>
                        La funci√≥n acumulada <i>F(x)</i> de una variable aleatoria continua indica la probabilidad de
                        que
                        la variable aleatoria <i>X</i> sea menor o igual a un valor dado <i>x</i>.
                    </p>
                    <div id="math-output">
                        \( F(x) = P(X \leq x) \)
                    </div>
                    <br>
                    <p>
                        Y la probabilidad de que <i>X</i> est√© en un intervalo [<i>a,b</i>] se calcula como 
                        <i>P</i>(<i>a < X ‚â§ b</i>)<i> = F</i>(<i>b</i>) - F</i>(<i>b</i>).
                    </p>
                </td>
            </tr>
            </tr>
            <tr>
                <td>3.2.5 C√°lculos de Probabilidad</td>
                <td>
                    Los c√°lculos de probabilidad para variables aleatorias continuas se realizan principalmente mediante
                    integrales de la funci√≥n de densidad de probabilidad (PDF) en intervalos espec√≠ficos, como se
                    indic√≥ anteriormente.
                </td>
            </tr>

            <!-- #####################################  TEMA 4 ##################################### -->

            <tr>
                <th colspan="2">
                    <h2>Tema 4: Distribuciones de Probabilidad</h2>
                </th>
            </tr>
            <tr>
                <th class="subtema-height">Subtema</th>
                <th>Definici√≥n</th>
            </tr>
            <tr>
                <td>4.1 Funci√≥n de probabilidad</td>
                <td>
                    <p>
                        Se define como una funci√≥n que asigna probabilidades a cada valor posible de la variable.
                        La funci√≥n de probabilidad asigna la probabilidad de que una variable aleatoria discreta
                        <i>X</i> tome un valor espec√≠fico <i>x</i>.
                    </p>
                    <div id="math-output">
                        \( P(X = x) \)
                    </div>
                </td>
            </tr>
            <tr>
                <td>4.2 Distribuci√≥n binomial</td>
                <td>
                    <p>
                        La distribuci√≥n binomial se utiliza para modelar la probabilidad de obtener un n√∫mero
                        espec√≠fico de √©xitos en un n√∫mero fijo de ensayos de Bernoulli con dos resultados posibles,
                        cada uno con la misma probabilidad de √©xito (<i>p</i>).
                        <br>
                        F√≥rmula de la funci√≥n de probabilidad:
                    </p>
                    <div id="math-output">
                        \( P(k; n, p) = \binom{n}{k} p^k (1 - p)^{n - k} \)
                    </div>
                    <p>
                        Donde <i>n</i> es el n√∫mero de ensayos de Bernoulli, <i>k</i> es el n√∫mero de √©xitos, y <i>p</i>
                        es la probabilidad de √©xito en un ensayo.
                        <br>
                        C√°lculo de la media:
                    <div id="math-output">
                        \( np \)
                    </div>
                    C√°lculo de la varianza:
                    <div id="math-output">
                        \( np(1 - p) \)
                    </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import binom

n = 10
p = 0.5
k=4
prob = binom.pmf(k, n, p)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.3 Distribuci√≥n hipergeom√©trica</td>
                <td>
                    <p>
                        La distribuci√≥n hipergeom√©trica modela la probabilidad de obtener un n√∫mero espec√≠fico
                        de elementos de inter√©s (√©xitos) en una muestra extra√≠da sin reemplazo de una poblaci√≥n
                        finita dividida en dos grupos.
                        <br>
                        F√≥rmula de la funci√≥n de probabilidad:
                    </p>
                    <div id="math-output">
                        \( P(k; N, n, K) = \frac{\binom{K}{k} \binom{N-K}{n-k}}{\binom{N}{n}} \)
                    </div>
                    <p>
                        Donde <i>N</i> es el tama√±o total de la poblaci√≥n, <i>K</i> es el n√∫mero de elementos de inter√©s
                        en la poblaci√≥n,
                        <i>n</i> es el tama√±o de la muestra y <i>k</i> es el n√∫mero de √©xitos en la muestra.
                        <br>
                        C√°lculo de la media:
                        <div id="math-output">
                            \( \frac{nK}{N} \)
                        </div>
                        C√°lculo de la varianza:
                        <div id="math-output">
                            \( \frac{nK (N-K)(N-n)}{N^2(N-1)} \)
                        </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import hypergeom
N = 100
n = 20
K = 10
k=4
prob = hypergeom.pmf(k, N, n, K)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.4 Distribuci√≥n de Poisson</td>
                <td>
                    <p>
                        La distribuci√≥n de Poisson se utiliza para modelar el n√∫mero de eventos de baja frecuencia
                        (eventos raros)
                        que ocurren en un intervalo de tiempo o espacio.
                        <br>
                        F√≥rmula de la funci√≥n de probabilidad:
                    </p>
                    <div id="math-output">
                        \( P(k; \lambda) = \frac{e^{-\lambda} \lambda^k}{k!} \)
                    </div>
                    <p>
                        Donde Œª es el n√∫mero promedio de eventos por intervalo de tiempo o espacio, y <i>k</i> es el
                        n√∫mero de
                        eventos que queremos modelar.
                        <br>
                        C√°lculo de la media:
                        <div id="math-output">
                            \( \lambda \)
                        </div>
                        C√°lculo de la varianza:
                        <div id="math-output">
                            \( \lambda \)
                        </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import poisson
lmbda = 3
k=2
prob = poisson.pmf(k, lmbda)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.5 Distribuci√≥n normal</td>
                <td>
                    <p>
                        La distribuci√≥n normal es utilizada para modelar una amplia variedad de fen√≥menos naturales y
                        sociales
                        debido a su forma de campana y propiedades estad√≠sticas bien conocidas.
                        <br>
                        Funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(x; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x - \mu)^2}{2 \sigma^2}} \)
                    </div>
                    <p>
                        Donde ùúá es la media y œÉ<sup>2</sup> es la varianza de la distribuci√≥n.
                        <br>
                        C√°lculo de la media:
                        <div id="math-output">
                            \( \mu \)
                        </div>
                        C√°lculo de la varianza:
                        <div id="math-output">
                            \( \sigma^2 \)
                        </div>
                    </p>
<pre>
<b> C√≥digo en Python</b>
<code class="python">from scipy.stats import norm
mu = 0
sigma = 1
x = 1.5
prob = norm.pdf(x, mu, sigma)
</code></pre>
                </td>
            </tr>
            <tr>
                <td>4.6 Distribuci√≥n T-student</td>
                <td>
                    <p>
                        La distribuci√≥n T-student se utiliza para inferencia estad√≠stica cuando el tama√±o de la
                        muestra es peque√±o y la varianza de la poblaci√≥n es desconocida.
                        <br>
                        F√≥rmula de la funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(t | \nu) = \frac{\Gamma\left(\frac{\nu + 1}{2}\right)}{\sqrt{\nu \pi} \Gamma\left(\frac{\nu}{2}\right) \left(1 + \frac{t^2}{\nu}\right)^{\frac{\nu + 1}{2}}} \)
                    </div>
                    <p>
                        Donde <i>t</i> es la variable aleatoria T de Student, <i>v</i> son los grados de libertad de la
                        distribuci√≥n
                        y <i>Œì</i>(‚ãÖ) denota la funci√≥n gamma, que para un entero <i>n</i> es (<i>n</i>-1)!.
                    </p>
                </td>
            </tr>
            <tr>
                <td>4.7 Distribuci√≥n Chi cuadrada</td>
                <td>
                    <p>
                        La distribuci√≥n Chi cuadrada se utiliza para pruebas de hip√≥tesis y para construir intervalos de
                        confianza
                        sobre la varianza de una poblaci√≥n normalmente distribuida.
                        <br>
                        Funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(x | \nu) = \frac{x^{\frac{\nu}{2} - 1} e^{-\frac{x}{2}}}{2^{\frac{\nu}{2}}
                        \Gamma\left(\frac{\nu}{2}\right)} \)
                    </div>
                    <p>
                        Donde <i>x</i> es la variable aleatoria Chi-cuadrado, <i>v</i> es el n√∫mero de grados de
                        libertad y <i>Œì</i>(‚ãÖ) denota la funci√≥n gamma.
                    </p>
                </td>
            </tr>
            <tr>
                <td>4.8 Distribuci√≥n F</td>
                <td>
                    <p>
                        La distribuci√≥n F se utiliza principalmente en an√°lisis de varianza (ANOVA) y en
                        comparaciones de varianzas entre dos o m√°s muestras.
                        <br>
                        Funci√≥n de densidad de probabilidad:
                    </p>
                    <div id="math-output">
                        \( f(x | d_1, d_2) = \frac{\Gamma\left(\frac{d_1 + d_2}{2}\right) \left(\frac{d_1}{d_2}\right)^{\frac{d_1}{2}} x^{\frac{d_1}{2} - 1}}{\Gamma\left(\frac{d_1}{2}\right) \Gamma\left(\frac{d_2}{2}\right) \left(1 + \frac{d_1 x}{d_2}\right)^{\frac{d_1 + d_2}{2}}} \)
                    </div>
                    <p>
                        Donde donde <i>d</i><sub>1</sub> y <i>d</i><sub>2</sub> son los grados de libertad de las dos muestras que se est√°n
                        comparando.
                    </p>
                </td>
            </tr>
        </table>
    </div>

    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/11.5.1/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</body>
</html>